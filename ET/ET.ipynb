{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we upload our packages\n",
    "import arcpy\n",
    "from arcpy import env  \n",
    "from arcpy.sa import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import random\n",
    "import psycopg2\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is to read in the CSV of our September 2023 data as dataframe\n",
    "csv_file_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\temp_data.csv\"\n",
    "temp_data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's remove any cells with NA values\n",
    "temp_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we must convert numeric columns to appropriate data types\n",
    "numeric_cols = ['high_F', 'low_F', 'precip', 'snow_inch', 'snowd_inch']\n",
    "temp_data[numeric_cols] = temp_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data also needs coordinate info for each point\n",
    "#We will use a Mesonet URL to gather reporting station location\n",
    "url = \"https://mesonet.agron.iastate.edu/sites/networks.php?network=MN_COOP&format=csv&nohtml=on\"\n",
    "\n",
    "# Read the CSV data from the URL into a data frame\n",
    "loc_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      nwsli        date      time  ...  snowd_inch      lat      lon\n",
      "0     NHPM5  2023-09-01  11:00 PM  ...         0.0  45.0100 -93.3792\n",
      "1     LMBM5  2023-09-01   7:00 AM  ...         0.0  44.2400 -95.3200\n",
      "2     LCHM5  2023-09-01   8:00 AM  ...         0.0  45.1279 -94.5348\n",
      "3     PKGM5  2023-09-01   8:00 AM  ...         0.0  47.2500 -93.5900\n",
      "4     CLDM5  2023-09-01   6:00 AM  ...         0.0  43.6309 -91.5027\n",
      "...     ...         ...       ...  ...         ...      ...      ...\n",
      "3480  KABM5  2023-09-30   7:00 AM  ...         0.0  46.4456 -93.0283\n",
      "3481  CLDM5  2023-09-30   6:00 AM  ...         0.0  43.6309 -91.5027\n",
      "3482  NHPM5  2023-09-30  11:00 PM  ...         0.0  45.0100 -93.3792\n",
      "3483  PKGM5  2023-09-30   8:00 AM  ...         0.0  47.2500 -93.5900\n",
      "3484  LMBM5  2023-09-30   7:00 AM  ...         0.0  44.2400 -95.3200\n",
      "\n",
      "[3485 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the \"lat\" and \"lon\" columns from df based on the matching \"nwsli\" and \"stid\" columns\n",
    "temp_data = pd.merge(temp_data, loc_df[['stid', 'lat', 'lon']], how='left', left_on='nwsli', right_on='stid')\n",
    "\n",
    "# Drop the redundant \"stid\" column\n",
    "temp_data.drop(columns=['stid'], inplace=True)\n",
    "\n",
    "# Display the updated precip_data data frame\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data falls within Minnesota boundary.\n"
     ]
    }
   ],
   "source": [
    "# Define Minnesota boundary box\n",
    "minnesota_boundary = Polygon([( -97.5, 43.0), (-89.0, 43.0), (-89.0, 49.5), (-97.5, 49.5)])\n",
    "\n",
    "# Check if the data falls within the Minnesota boundary\n",
    "temp_data['Coordinates'] = list(zip(temp_data.lon, temp_data.lat))\n",
    "temp_data['Coordinates'] = temp_data['Coordinates'].apply(Point)\n",
    "gdf = gpd.GeoDataFrame(temp_data, geometry='Coordinates')\n",
    "\n",
    "within_minnesota = gdf[gdf.geometry.within(minnesota_boundary)]\n",
    "if len(within_minnesota) == 0:\n",
    "    print(\"No data falls within Minnesota boundary.\")\n",
    "else:\n",
    "    print(\"Data falls within Minnesota boundary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'date' column after conversion: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the \"Date\" column to datetime type\n",
    "temp_data['date'] = pd.to_datetime(temp_data['date'])\n",
    "\n",
    "# Check the type of the \"Date\" column after conversion\n",
    "date_column_type = temp_data['date'].dtype\n",
    "\n",
    "print(\"Type of 'date' column after conversion:\", date_column_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a date (YYYY-MM-DD format): 2023-09-09\n",
      "      nwsli       date     time  ...      lat      lon               Coordinates\n",
      "935   RSMM5 2023-09-09  8:00 AM  ...  44.7178 -93.0975  POINT (-93.0975 44.7178)\n",
      "936   MIAM5 2023-09-09  6:00 PM  ...  45.1219 -95.9269  POINT (-95.9269 45.1219)\n",
      "937   GNFM5 2023-09-09  8:00 AM  ...  48.1667 -90.8875  POINT (-90.8875 48.1667)\n",
      "938   MABM5 2023-09-09  7:00 AM  ...  43.5241 -91.7616  POINT (-91.7616 43.5241)\n",
      "939   HSTM5 2023-09-09  5:00 AM  ...  44.7597 -92.8689  POINT (-92.8689 44.7597)\n",
      "...     ...        ...      ...  ...      ...      ...                       ...\n",
      "1045  GLDM5 2023-09-09  9:00 AM  ...  44.5565 -94.2207  POINT (-94.2207 44.5565)\n",
      "1046  WASM5 2023-09-09  8:00 AM  ...  44.0707 -93.5264  POINT (-93.5264 44.0707)\n",
      "1047  TOWM5 2023-09-09  7:00 AM  ...  47.7553 -92.2858  POINT (-92.2858 47.7553)\n",
      "1048  CSLM5 2023-09-09  8:00 AM  ...  47.3847 -94.6147  POINT (-94.6147 47.3847)\n",
      "1049  AGAM5 2023-09-09  8:00 AM  ...  48.3000 -95.9833     POINT (-95.9833 48.3)\n",
      "\n",
      "[115 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#Now we need to choose the date which we will interpolate for\n",
    "input_date = input(\"Enter a date (YYYY-MM-DD format): \")\n",
    "\n",
    "# Convert input string to datetime object\n",
    "input_date = pd.to_datetime(input_date)\n",
    "\n",
    "# Filter DataFrame based on the input date\n",
    "temp_data = temp_data[temp_data['date'] == input_date]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will calculate average temperature for each row\n",
    "temp_data['avg_temp'] = (temp_data['high_F'] + temp_data['low_F']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then these next cells will calculate evapotranspiration\n",
    "# First it defines the constant for the Hargreaves method\n",
    "constant = 0.0023\n",
    "\n",
    "# Convert 'date' column to datetime object\n",
    "temp_data['date'] = pd.to_datetime(temp_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      nwsli       date     time  ...               Coordinates  avg_temp        ET\n",
      "935   RSMM5 2023-09-09  8:00 AM  ...  POINT (-93.0975 44.7178)      63.0  1.024494\n",
      "936   MIAM5 2023-09-09  6:00 PM  ...  POINT (-95.9269 45.1219)      70.5  1.100771\n",
      "937   GNFM5 2023-09-09  8:00 AM  ...  POINT (-90.8875 48.1667)      57.5  0.718715\n",
      "938   MABM5 2023-09-09  7:00 AM  ...  POINT (-91.7616 43.5241)      56.5  0.988060\n",
      "939   HSTM5 2023-09-09  5:00 AM  ...  POINT (-92.8689 44.7597)      64.0  0.927676\n",
      "...     ...        ...      ...  ...                       ...       ...       ...\n",
      "1045  GLDM5 2023-09-09  9:00 AM  ...  POINT (-94.2207 44.5565)      67.5  0.947001\n",
      "1046  WASM5 2023-09-09  8:00 AM  ...  POINT (-93.5264 44.0707)      64.0  1.002005\n",
      "1047  TOWM5 2023-09-09  7:00 AM  ...  POINT (-92.2858 47.7553)      59.5  0.858185\n",
      "1048  CSLM5 2023-09-09  8:00 AM  ...  POINT (-94.6147 47.3847)      64.0  0.846848\n",
      "1049  AGAM5 2023-09-09  8:00 AM  ...     POINT (-95.9833 48.3)      61.5  0.800179\n",
      "\n",
      "[115 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Then this cell calculates ET using the Hargreaves method for each row\n",
    "ET0_values = []\n",
    "for index, row in temp_data.iterrows():\n",
    "    avg_temperature = row['avg_temp']\n",
    "    temperature_range = row['high_F'] - row['low_F']\n",
    "    \n",
    "    # Calculate the day of the year\n",
    "    day_of_year = row['date'].dayofyear\n",
    "    \n",
    "    # Calculate ET0 using the Hargreaves method\n",
    "    ET0 = constant * (avg_temperature + 17.8) * (temperature_range ** 0.5) * (1.0 + 0.033 * np.sin(np.deg2rad(360 * (day_of_year - 81) / 365)))\n",
    "    \n",
    "    ET0_values.append(ET0)\n",
    "\n",
    "# Add the calculated ET0 values as a new column to the DataFrame\n",
    "temp_data['ET'] = ET0_values\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(temp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class 'Points' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Then we need to create a feature class for our points\n",
    "output_fc = 'Points'\n",
    "\n",
    "# Create a new feature class\n",
    "arcpy.management.CreateFeatureclass(\n",
    "    arcpy.env.workspace,\n",
    "    output_fc,\n",
    "    'POINT',\n",
    "    spatial_reference=arcpy.SpatialReference(4326)  # WGS84 Geographic Coordinate System\n",
    ")\n",
    "\n",
    "# Check the data type of the 'ET' column in the DataFrame\n",
    "et_dtype = temp_data['ET'].dtype\n",
    "\n",
    "# Add field to store ET data, ensuring correct data type\n",
    "if et_dtype == 'float64':\n",
    "    arcpy.management.AddField(output_fc, 'ET', 'FLOAT')\n",
    "else:\n",
    "    arcpy.management.AddField(output_fc, 'ET', 'DOUBLE')\n",
    "\n",
    "# Add 'date' and 'nwsli' fields\n",
    "arcpy.management.AddField(output_fc, 'date', 'DATE')\n",
    "arcpy.management.AddField(output_fc, 'nwsli', 'TEXT')\n",
    "\n",
    "\n",
    "\n",
    "# Open an insert cursor\n",
    "with arcpy.da.InsertCursor(output_fc, ['SHAPE@XY', 'ET', 'date', 'nwsli']) as cursor:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in temp_data.iterrows():\n",
    "        # Extract lat, lon, ET, date, and nwsli values\n",
    "        lat = row['lat']\n",
    "        lon = row['lon']\n",
    "        date = row['date']\n",
    "        ET = row['ET']\n",
    "        nwsli = row['nwsli']\n",
    "        \n",
    "        # Create a point geometry\n",
    "        point = arcpy.Point(lon, lat)\n",
    "        point_geometry = arcpy.PointGeometry(point)\n",
    "        \n",
    "        # Insert the point feature with the ET, date, and nwsli values\n",
    "        cursor.insertRow([point_geometry, ET, date, nwsli])\n",
    "\n",
    "print(f\"Feature class '{output_fc}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the IDW interpolation\n",
    "outIDW = Idw(\"Points.shp\", \"ET\")\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\IDW_ETPoints.tif\"\n",
    "outIDW.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the ordinary kriging interpolation\n",
    "outKriging = Kriging(\"Points.shp\", \"ET\", KrigingModelOrdinary(\"SPHERICAL\", 0.021507), 0.0215068000000001)\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\Kriging_ETPoints.tif\"\n",
    "outKriging.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the universal kriging interpolation\n",
    "outKriging = Kriging(\"Points.shp\", \"ET\", KrigingModelUniversal(\"SPHERICAL\", 0.021507), 0.0215068000000001)\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\Univ_Kriging_ETPoints.tif\"\n",
    "outKriging.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, May 6, 2024 1:17:55 AM\",\"Building Pyramids...\",\"Succeeded at Monday, May 6, 2024 1:17:59 AM (Elapsed Time: 4.19 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\GIS 5572 Final\\\\GIS 5572 Final.gdb\\\\Univ_Kriging_ET_Resample'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This performs the resampling of the tifs to reduce the number of points needed\n",
    "arcpy.management.Resample(\n",
    "    in_raster=r\"Idw_ETPoints.tif\",\n",
    "    out_raster=r\"Idw_ET_Resample\",\n",
    "    cell_size=\"0.2 0.2\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "\n",
    "arcpy.management.Resample(\n",
    "    in_raster=r\"Kriging_ETPoints.tif\",\n",
    "    out_raster=r\"Kriging_ET_Resample\",\n",
    "    cell_size=\"0.2 0.2\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "\n",
    "arcpy.management.Resample(\n",
    "    in_raster=r\"Univ_Kriging_ETPoints.tif\",\n",
    "    out_raster=r\"Univ_Kriging_ET_Resample\",\n",
    "    cell_size=\"0.2 0.2\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, May 6, 2024 1:18:25 AM\",\"Succeeded at Monday, May 6, 2024 1:18:37 AM (Elapsed Time: 12.59 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\GIS 5572 Final\\\\GIS 5572 Final.gdb\\\\Univ_Kriging_ET_Point'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This converts the raster to points\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=r\"Idw_ET_Resample\",\n",
    "    out_point_features=r\"Idw_ET_Point\",\n",
    "    raster_field=\"value\"\n",
    ")\n",
    "\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=r\"Kriging_ET_Resample\",\n",
    "    out_point_features=r\"Kriging_ET_Point\",\n",
    "    raster_field=\"value\"\n",
    ")\n",
    "\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=r\"Univ_Kriging_ET_Resample\",\n",
    "    out_point_features=r\"Univ_Kriging_ET_Point\",\n",
    "    raster_field=\"value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC\n",
    "# exploratory Interpolation\n",
    "arcpy.ga.ExploratoryInterpolation(\n",
    "    in_features=\"Points\",\n",
    "    value_field=\"ET\",\n",
    "    out_cv_table=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\GIS 5572 Final.gdb\\ExploratoryInterpolation1\",\n",
    "    out_geostat_layer=None,\n",
    "    interp_methods=\"ORDINARY_KRIGING;UNIVERSAL_KRIGING;IDW\",\n",
    "    comparison_method=\"SINGLE\",\n",
    "    criterion=\"ACCURACY\",\n",
    "    criteria_hierarchy=\"ACCURACY PERCENT #\",\n",
    "    weighted_criteria=\"ACCURACY 1\",\n",
    "    exclusion_criteria=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete\n"
     ]
    }
   ],
   "source": [
    "#This will export the IDW points to a PostGIS database\n",
    "arcpy.conversion.ExportFeatures(\n",
    "    in_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\GIS 5572 Final.gdb\\Idw_ET_Point\",\n",
    "    out_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\PostgreSQL-34-final_project(postgres).sde\\final_project.postgres.et_data\"\n",
    ")\n",
    "print(\"Export complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
