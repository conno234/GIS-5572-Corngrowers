{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we upload our packages\n",
    "import arcpy\n",
    "from arcpy import env  \n",
    "from arcpy.sa import *\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import random\n",
    "import psycopg2\n",
    "from shapely.geometry import Point, Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next is to read in the CSV of our September 2023 data as dataframe\n",
    "csv_file_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\temp_data.csv\"\n",
    "temp_data = pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we must convert numeric columns to appropriate data types\n",
    "numeric_cols = ['high_F', 'low_F', 'precip', 'snow_inch', 'snowd_inch']\n",
    "temp_data[numeric_cols] = temp_data[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This data also needs coordinate info for each point\n",
    "#We will use a Mesonet URL to gather reporting station location\n",
    "url = \"https://mesonet.agron.iastate.edu/sites/networks.php?network=MN_COOP&format=csv&nohtml=on\"\n",
    "\n",
    "# Read the CSV data from the URL into a data frame\n",
    "loc_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      nwsli        date      time  ...  snowd_inch       lat       lon\n",
      "0     MOOM5  2023-09-01       NaN  ...         NaN  46.45000 -92.75780\n",
      "1     TWRM5  2023-09-01       NaN  ...         NaN  46.96670 -95.66670\n",
      "2     HKHM5  2023-09-01   7:00 AM  ...         NaN  43.76372 -91.34814\n",
      "3     BABM5  2023-09-01       NaN  ...         NaN  47.71210 -91.95330\n",
      "4     NHPM5  2023-09-01  11:00 PM  ...         0.0  45.01000 -93.37920\n",
      "...     ...         ...       ...  ...         ...       ...       ...\n",
      "5695  NHPM5  2023-09-30  11:00 PM  ...         0.0  45.01000 -93.37920\n",
      "5696  PKGM5  2023-09-30   8:00 AM  ...         0.0  47.25000 -93.59000\n",
      "5697  PELM5  2023-09-30   8:00 AM  ...         0.0  46.58330 -96.08890\n",
      "5698  LCHM5  2023-09-30   8:00 AM  ...         0.0  45.12790 -94.53480\n",
      "5699  LMBM5  2023-09-30   7:00 AM  ...         0.0  44.24000 -95.32000\n",
      "\n",
      "[5700 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the \"lat\" and \"lon\" columns from df based on the matching \"nwsli\" and \"stid\" columns\n",
    "temp_data = pd.merge(temp_data, loc_df[['stid', 'lat', 'lon']], how='left', left_on='nwsli', right_on='stid')\n",
    "\n",
    "# Drop the redundant \"stid\" column\n",
    "temp_data.drop(columns=['stid'], inplace=True)\n",
    "\n",
    "# Display the updated precip_data data frame\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data falls within Minnesota boundary.\n"
     ]
    }
   ],
   "source": [
    "# Define Minnesota boundary box\n",
    "minnesota_boundary = Polygon([( -97.5, 43.0), (-89.0, 43.0), (-89.0, 49.5), (-97.5, 49.5)])\n",
    "\n",
    "# Check if the data falls within the Minnesota boundary\n",
    "temp_data['Coordinates'] = list(zip(temp_data.lon, temp_data.lat))\n",
    "temp_data['Coordinates'] = temp_data['Coordinates'].apply(Point)\n",
    "gdf = gpd.GeoDataFrame(temp_data, geometry='Coordinates')\n",
    "\n",
    "within_minnesota = gdf[gdf.geometry.within(minnesota_boundary)]\n",
    "if len(within_minnesota) == 0:\n",
    "    print(\"No data falls within Minnesota boundary.\")\n",
    "else:\n",
    "    print(\"Data falls within Minnesota boundary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'date' column after conversion: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the \"Date\" column to datetime type\n",
    "temp_data['date'] = pd.to_datetime(temp_data['date'])\n",
    "\n",
    "# Check the type of the \"Date\" column after conversion\n",
    "date_column_type = temp_data['date'].dtype\n",
    "\n",
    "print(\"Type of 'date' column after conversion:\", date_column_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a date (YYYY-MM-DD format): 2023-09-16\n",
      "      nwsli       date      time  ...  snowd_inch      lat      lon\n",
      "2850  NISM5 2023-09-16       NaN  ...         NaN  46.5000 -94.2667\n",
      "2851  CRLM5 2023-09-16   8:00 AM  ...         0.0  46.6700 -94.1100\n",
      "2852  BWNM5 2023-09-16   8:00 AM  ...         0.0  44.7335 -94.3417\n",
      "2853  WRUM5 2023-09-16  10:00 PM  ...         NaN  48.9008 -95.4006\n",
      "2854  RUDM5 2023-09-16   7:00 AM  ...         0.0  43.8052 -91.7501\n",
      "...     ...        ...       ...  ...         ...      ...      ...\n",
      "3035  LSAM5 2023-09-16       NaN  ...         NaN  44.9783 -93.2469\n",
      "3036  ALXM5 2023-09-16   6:00 AM  ...         NaN  45.8782 -95.3827\n",
      "3037  BLHM5 2023-09-16       NaN  ...         NaN  45.8608 -94.3600\n",
      "3038  KIMM5 2023-09-16   6:00 AM  ...         0.0  45.3533 -94.3056\n",
      "3039  MPXM5 2023-09-16  11:00 PM  ...         0.0  44.8496 -93.5644\n",
      "\n",
      "[190 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Now we need to choose the date which we will interpolate for\n",
    "input_date = input(\"Enter a date (YYYY-MM-DD format): \")\n",
    "\n",
    "# Convert input string to datetime object\n",
    "input_date = pd.to_datetime(input_date)\n",
    "\n",
    "# Filter DataFrame based on the input date\n",
    "temp_data = temp_data[temp_data['date'] == input_date]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwsli</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>high_F</th>\n",
       "      <th>low_F</th>\n",
       "      <th>precip</th>\n",
       "      <th>snow_inch</th>\n",
       "      <th>snowd_inch</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>avg_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>NISM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.5000</td>\n",
       "      <td>-94.2667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>CRLM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>71.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.6700</td>\n",
       "      <td>-94.1100</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>BWNM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>75.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.7335</td>\n",
       "      <td>-94.3417</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>WRUM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>10:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.9008</td>\n",
       "      <td>-95.4006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>RUDM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>7:00 AM</td>\n",
       "      <td>67.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.8052</td>\n",
       "      <td>-91.7501</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>LSAM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.9783</td>\n",
       "      <td>-93.2469</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>ALXM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>6:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8782</td>\n",
       "      <td>-95.3827</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>BLHM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8608</td>\n",
       "      <td>-94.3600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>KIMM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>6:00 AM</td>\n",
       "      <td>76.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.3533</td>\n",
       "      <td>-94.3056</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>MPXM5</td>\n",
       "      <td>2023-09-16</td>\n",
       "      <td>11:00 PM</td>\n",
       "      <td>70.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.8496</td>\n",
       "      <td>-93.5644</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      nwsli       date      time  ...      lat      lon  avg_temp\n",
       "2850  NISM5 2023-09-16       NaN  ...  46.5000 -94.2667       NaN\n",
       "2851  CRLM5 2023-09-16   8:00 AM  ...  46.6700 -94.1100      60.5\n",
       "2852  BWNM5 2023-09-16   8:00 AM  ...  44.7335 -94.3417      63.0\n",
       "2853  WRUM5 2023-09-16  10:00 PM  ...  48.9008 -95.4006       NaN\n",
       "2854  RUDM5 2023-09-16   7:00 AM  ...  43.8052 -91.7501      60.0\n",
       "...     ...        ...       ...  ...      ...      ...       ...\n",
       "3035  LSAM5 2023-09-16       NaN  ...  44.9783 -93.2469      61.0\n",
       "3036  ALXM5 2023-09-16   6:00 AM  ...  45.8782 -95.3827       NaN\n",
       "3037  BLHM5 2023-09-16       NaN  ...  45.8608 -94.3600       NaN\n",
       "3038  KIMM5 2023-09-16   6:00 AM  ...  45.3533 -94.3056      63.0\n",
       "3039  MPXM5 2023-09-16  11:00 PM  ...  44.8496 -93.5644      58.5\n",
       "\n",
       "[190 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell will calculate average temperature for each row\n",
    "temp_data['avg_temp'] = (temp_data['high_F'] + temp_data['low_F']) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then these next cells will calculate evapotranspiration\n",
    "# First it defines the constant for the Hargreaves method\n",
    "constant = 0.0023\n",
    "\n",
    "# Convert 'date' column to datetime object\n",
    "temp_data['date'] = pd.to_datetime(temp_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      nwsli       date      time  high_F  ...      lat      lon  avg_temp        ET\n",
      "2850  NISM5 2023-09-16       NaN     NaN  ...  46.5000 -94.2667       NaN       NaN\n",
      "2851  CRLM5 2023-09-16   8:00 AM    71.0  ...  46.6700 -94.1100      60.5  0.827384\n",
      "2852  BWNM5 2023-09-16   8:00 AM    75.0  ...  44.7335 -94.3417      63.0  0.912751\n",
      "2853  WRUM5 2023-09-16  10:00 PM     NaN  ...  48.9008 -95.4006       NaN       NaN\n",
      "2854  RUDM5 2023-09-16   7:00 AM    67.0  ...  43.8052 -91.7501      60.0  0.671242\n",
      "...     ...        ...       ...     ...  ...      ...      ...       ...       ...\n",
      "3035  LSAM5 2023-09-16       NaN    68.0  ...  44.9783 -93.2469      61.0  0.679870\n",
      "3036  ALXM5 2023-09-16   6:00 AM     NaN  ...  45.8782 -95.3827       NaN       NaN\n",
      "3037  BLHM5 2023-09-16       NaN     NaN  ...  45.8608 -94.3600       NaN       NaN\n",
      "3038  KIMM5 2023-09-16   6:00 AM    76.0  ...  45.3533 -94.3056      63.0  0.950022\n",
      "3039  MPXM5 2023-09-16  11:00 PM    70.0  ...  44.8496 -93.5644      58.5  0.843770\n",
      "\n",
      "[190 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Then this cell calculates ET using the Hargreaves method for each row\n",
    "ET0_values = []\n",
    "for index, row in temp_data.iterrows():\n",
    "    avg_temperature = row['avg_temp']\n",
    "    temperature_range = row['high_F'] - row['low_F']\n",
    "    \n",
    "    # Calculate the day of the year\n",
    "    day_of_year = row['date'].dayofyear\n",
    "    \n",
    "    # Calculate ET0 using the Hargreaves method\n",
    "    ET0 = constant * (avg_temperature + 17.8) * (temperature_range ** 0.5) * (1.0 + 0.033 * np.sin(np.deg2rad(360 * (day_of_year - 81) / 365)))\n",
    "    \n",
    "    ET0_values.append(ET0)\n",
    "\n",
    "# Add the calculated ET0 values as a new column to the DataFrame\n",
    "temp_data['ET'] = ET0_values\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(temp_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will determine how many null values lie in our data\n",
    "# This line will calculate the total number of rows\n",
    "total_rows = temp_data.shape[0]\n",
    "\n",
    "# Calculate the number of null values in avg_temp and ET columns\n",
    "null_avg_temp = temp_data['avg_temp'].isnull().sum()\n",
    "null_ET = temp_data['ET'].isnull().sum()\n",
    "\n",
    "# Calculate the percentage of null values\n",
    "null_avg_temp_percentage = (null_avg_temp / total_rows) * 100\n",
    "null_ET_percentage = (null_ET / total_rows) * 100\n",
    "\n",
    "# Define the threshold for warning\n",
    "threshold = 50\n",
    "\n",
    "# Finally, this line will let us know if the percentage of null values exceeds the threshold for either column\n",
    "if null_avg_temp_percentage > threshold or null_ET_percentage > threshold:\n",
    "    print(\"Warning: The percentage of null values in either avg_temp or ET column exceeds 50%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class 'Points' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Then we need to create a feature class for our points\n",
    "output_fc = 'Points'\n",
    "\n",
    "# Create a new feature class\n",
    "arcpy.management.CreateFeatureclass(\n",
    "    arcpy.env.workspace,\n",
    "    output_fc,\n",
    "    'POINT',\n",
    "    spatial_reference=arcpy.SpatialReference(4326)  # WGS84 Geographic Coordinate System\n",
    ")\n",
    "\n",
    "# Check the data type of the 'ET' column in the DataFrame\n",
    "et_dtype = temp_data['ET'].dtype\n",
    "\n",
    "# Add field to store ET data, ensuring correct data type\n",
    "if et_dtype == 'float64':\n",
    "    arcpy.management.AddField(output_fc, 'ET', 'FLOAT')\n",
    "else:\n",
    "    arcpy.management.AddField(output_fc, 'ET', 'DOUBLE')\n",
    "\n",
    "# Add 'date' and 'nwsli' fields\n",
    "arcpy.management.AddField(output_fc, 'date', 'DATE')\n",
    "arcpy.management.AddField(output_fc, 'nwsli', 'TEXT')\n",
    "\n",
    "# Add 'GDD' field\n",
    "arcpy.management.AddField(output_fc, 'GDD', 'FLOAT')\n",
    "\n",
    "# Open an insert cursor\n",
    "with arcpy.da.InsertCursor(output_fc, ['SHAPE@XY', 'ET', 'date', 'nwsli', 'GDD']) as cursor:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in temp_data.iterrows():\n",
    "        # Extract lat, lon, ET, GDD, date, and nwsli values\n",
    "        lat = row['lat']\n",
    "        lon = row['lon']\n",
    "        date = row['date']\n",
    "        ET = row['ET']\n",
    "        GDD = row['GDD']  # Fetch GDD value\n",
    "        nwsli = row['nwsli']\n",
    "        \n",
    "        # Create a point geometry\n",
    "        point = arcpy.Point(lon, lat)\n",
    "        point_geometry = arcpy.PointGeometry(point)\n",
    "        \n",
    "        # Insert the point feature with the ET, GDD, date, and nwsli values\n",
    "        cursor.insertRow([point_geometry, ET, date, nwsli, GDD])\n",
    "\n",
    "print(f\"Feature class '{output_fc}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the IDW interpolation\n",
    "outIDW = Idw(\"Points.shp\", \"ET\")\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\IDW_ETPoints.tif\"\n",
    "outIDW.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the ordinary kriging interpolation\n",
    "outKriging = Kriging(\"Points.shp\", \"ET\", KrigingModelOrdinary(\"SPHERICAL\", 0.021507), 0.0215068000000001)\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\Kriging_ETPoints.tif\"\n",
    "outKriging.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This performs the universal kriging interpolation\n",
    "outKriging = Kriging(\"Points.shp\", \"ET\", KrigingModelUniversal(\"SPHERICAL\", 0.021507), 0.0215068000000001)\n",
    "output_path = r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\Univ_Kriging_ETPoints.tif\"\n",
    "outKriging.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, May 5, 2024 4:34:52 PM\",\"Building Pyramids...\",\"Succeeded at Sunday, May 5, 2024 4:35:05 PM (Elapsed Time: 12.81 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\GIS 5572 Final\\\\GIS 5572 Final.gdb\\\\Univ_Kriging_ET_Resample'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This performs the resampling of the tifs to reduce the number of points needed\n",
    "arcpy.management.Resample(\n",
    "    in_raster=r\"Idw_ETPoints.tif\",\n",
    "    out_raster=r\"Idw_ET_Resample\",\n",
    "    cell_size=\"0.2 0.2\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "\n",
    "arcpy.management.Resample(\n",
    "    in_raster=r\"Kriging_ETPoints.tif\",\n",
    "    out_raster=r\"Kriging_ET_Resample\",\n",
    "    cell_size=\"0.2 0.2\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")\n",
    "\n",
    "arcpy.management.Resample(\n",
    "    in_raster=r\"Univ_Kriging_ETPoints.tif\",\n",
    "    out_raster=r\"Univ_Kriging_ET_Resample\",\n",
    "    cell_size=\"0.2 0.2\",\n",
    "    resampling_type=\"NEAREST\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, May 5, 2024 4:35:27 PM\",\"Succeeded at Sunday, May 5, 2024 4:35:46 PM (Elapsed Time: 18.54 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\GIS 5572 Final\\\\GIS 5572 Final.gdb\\\\Univ_Kriging_ET_Point'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This converts the raster to points\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=r\"Idw_ET_Resample\",\n",
    "    out_point_features=r\"Idw_ET_Point\",\n",
    "    raster_field=\"value\"\n",
    ")\n",
    "\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=r\"Kriging_ET_Resample\",\n",
    "    out_point_features=r\"Kriging_ET_Point\",\n",
    "    raster_field=\"value\"\n",
    ")\n",
    "\n",
    "arcpy.conversion.RasterToPoint(\n",
    "    in_raster=r\"Univ_Kriging_ET_Resample\",\n",
    "    out_point_features=r\"Univ_Kriging_ET_Point\",\n",
    "    raster_field=\"value\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, May 5, 2024 4:32:16 PM\",\"Calculating Ordinary Kriging – Default\",\"\\r\\nWarning(s) for dataset: Points\",\"WARNING 040402: NODATA value ignored. ObjectID = 1\",\"WARNING 040402: NODATA value ignored. ObjectID = 4\",\"WARNING 040402: NODATA value ignored. ObjectID = 7\",\"WARNING 040402: NODATA value ignored. ObjectID = 8\",\"WARNING 040402: NODATA value ignored. ObjectID = 9\",\"WARNING 040402: NODATA value ignored. ObjectID = 18\",\"WARNING 040402: NODATA value ignored. ObjectID = 19\",\"WARNING 040402: NODATA value ignored. ObjectID = 20\",\"WARNING 040402: NODATA value ignored. ObjectID = 21\",\"WARNING 040402: NODATA value ignored. ObjectID = 22\",\"WARNING 040109: The maximum number of messages for the previous warning has been reached.\",\"Calculating Ordinary Kriging – Optimized\",\"\\r\\nWarning(s) for dataset: Points\",\"WARNING 040402: NODATA value ignored. ObjectID = 1\",\"WARNING 040402: NODATA value ignored. ObjectID = 4\",\"WARNING 040402: NODATA value ignored. ObjectID = 7\",\"WARNING 040402: NODATA value ignored. ObjectID = 8\",\"WARNING 040402: NODATA value ignored. ObjectID = 9\",\"WARNING 040402: NODATA value ignored. ObjectID = 18\",\"WARNING 040402: NODATA value ignored. ObjectID = 19\",\"WARNING 040402: NODATA value ignored. ObjectID = 20\",\"WARNING 040402: NODATA value ignored. ObjectID = 21\",\"WARNING 040402: NODATA value ignored. ObjectID = 22\",\"WARNING 040109: The maximum number of messages for the previous warning has been reached.\",\"Calculating Universal Kriging – Default\",\"\\r\\nWarning(s) for dataset: Points\",\"WARNING 040402: NODATA value ignored. ObjectID = 1\",\"WARNING 040402: NODATA value ignored. ObjectID = 4\",\"WARNING 040402: NODATA value ignored. ObjectID = 7\",\"WARNING 040402: NODATA value ignored. ObjectID = 8\",\"WARNING 040402: NODATA value ignored. ObjectID = 9\",\"WARNING 040402: NODATA value ignored. ObjectID = 18\",\"WARNING 040402: NODATA value ignored. ObjectID = 19\",\"WARNING 040402: NODATA value ignored. ObjectID = 20\",\"WARNING 040402: NODATA value ignored. ObjectID = 21\",\"WARNING 040402: NODATA value ignored. ObjectID = 22\",\"WARNING 040109: The maximum number of messages for the previous warning has been reached.\",\"Calculating Universal Kriging – Optimized\",\"\\r\\nWarning(s) for dataset: Points\",\"WARNING 040402: NODATA value ignored. ObjectID = 1\",\"WARNING 040402: NODATA value ignored. ObjectID = 4\",\"WARNING 040402: NODATA value ignored. ObjectID = 7\",\"WARNING 040402: NODATA value ignored. ObjectID = 8\",\"WARNING 040402: NODATA value ignored. ObjectID = 9\",\"WARNING 040402: NODATA value ignored. ObjectID = 18\",\"WARNING 040402: NODATA value ignored. ObjectID = 19\",\"WARNING 040402: NODATA value ignored. ObjectID = 20\",\"WARNING 040402: NODATA value ignored. ObjectID = 21\",\"WARNING 040402: NODATA value ignored. ObjectID = 22\",\"WARNING 040109: The maximum number of messages for the previous warning has been reached.\",\"Calculating Inverse Distance Weighted - Default\",\"\\r\\nWarning(s) for dataset: Points\",\"WARNING 040402: NODATA value ignored. ObjectID = 1\",\"WARNING 040402: NODATA value ignored. ObjectID = 4\",\"WARNING 040402: NODATA value ignored. ObjectID = 7\",\"WARNING 040402: NODATA value ignored. ObjectID = 8\",\"WARNING 040402: NODATA value ignored. ObjectID = 9\",\"WARNING 040402: NODATA value ignored. ObjectID = 18\",\"WARNING 040402: NODATA value ignored. ObjectID = 19\",\"WARNING 040402: NODATA value ignored. ObjectID = 20\",\"WARNING 040402: NODATA value ignored. ObjectID = 21\",\"WARNING 040402: NODATA value ignored. ObjectID = 22\",\"WARNING 040109: The maximum number of messages for the previous warning has been reached.\",\"Calculating Inverse Distance Weighted - Optimized\",\"\\r\\nWarning(s) for dataset: Points\",\"WARNING 040402: NODATA value ignored. ObjectID = 1\",\"WARNING 040402: NODATA value ignored. ObjectID = 4\",\"WARNING 040402: NODATA value ignored. ObjectID = 7\",\"WARNING 040402: NODATA value ignored. ObjectID = 8\",\"WARNING 040402: NODATA value ignored. ObjectID = 9\",\"WARNING 040402: NODATA value ignored. ObjectID = 18\",\"WARNING 040402: NODATA value ignored. ObjectID = 19\",\"WARNING 040402: NODATA value ignored. ObjectID = 20\",\"WARNING 040402: NODATA value ignored. ObjectID = 21\",\"WARNING 040402: NODATA value ignored. ObjectID = 22\",\"WARNING 040109: The maximum number of messages for the previous warning has been reached.\",\" \\n\",\"--------------------------------------------\",\"RANK | NAME\",\"--------------------------------------------\",\"\\n\",\"1    | Universal Kriging – Optimized\",\"\\n\",\"2    | Ordinary Kriging – Optimized\",\"\\n\",\"3    | Inverse Distance Weighted - Optimized\",\"\\n\",\"4    | Universal Kriging – Default\",\"\\n\",\"5    | Inverse Distance Weighted - Default\",\"\\n\",\"6    | Ordinary Kriging – Default\",\"--------------------------------------------\",\"Succeeded at Sunday, May 5, 2024 4:32:24 PM (Elapsed Time: 7.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\conno\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\GIS 5572 Final\\\\GIS 5572 Final.gdb\\\\ExploratoryInterpolation1'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QC\n",
    "# exploratory Interpolation\n",
    "arcpy.ga.ExploratoryInterpolation(\n",
    "    in_features=\"Points\",\n",
    "    value_field=\"ET\",\n",
    "    out_cv_table=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\GIS 5572 Final.gdb\\ExploratoryInterpolation1\",\n",
    "    out_geostat_layer=None,\n",
    "    interp_methods=\"ORDINARY_KRIGING;UNIVERSAL_KRIGING;IDW\",\n",
    "    comparison_method=\"SINGLE\",\n",
    "    criterion=\"ACCURACY\",\n",
    "    criteria_hierarchy=\"ACCURACY PERCENT #\",\n",
    "    weighted_criteria=\"ACCURACY 1\",\n",
    "    exclusion_criteria=None\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete\n"
     ]
    }
   ],
   "source": [
    "#This will export the Universal Kriging points to a PostGIS database\n",
    "arcpy.conversion.ExportFeatures(\n",
    "    in_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\GIS 5572 Final.gdb\\Univ_Kriging_ET_Point\",\n",
    "    out_features=r\"C:\\Users\\conno\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS 5572 Final\\PostgreSQL-34-final_project(postgres).sde\\final_project.postgres.et_data\"\n",
    ")\n",
    "print(\"Export complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
